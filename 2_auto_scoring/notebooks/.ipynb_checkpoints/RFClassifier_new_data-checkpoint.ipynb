{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>misspelt</th>\n",
       "      <th>correct</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>n_top500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>6</td>\n",
       "      <td>There were many obstacles that the builders fa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>6</td>\n",
       "      <td>Him from the start, there would have been many...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>6</td>\n",
       "      <td>In the passage The Mooring Mast by Marcia Amid...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essay_set                                              essay  \\\n",
       "essay_id                                                                 \n",
       "14834             6  There were many obstacles that the builders fa...   \n",
       "14835             6  Him from the start, there would have been many...   \n",
       "14836             6  The builders of the Empire State Building face...   \n",
       "14837             6  In the passage The Mooring Mast by Marcia Amid...   \n",
       "14838             6  The builders of the Empire State Building face...   \n",
       "\n",
       "          rater1_domain1  rater2_domain1  domain1_score  misspelt  correct  \\\n",
       "essay_id                                                                     \n",
       "14834                2.0             2.0            2.0         6      116   \n",
       "14835                3.0             3.0            3.0        11      169   \n",
       "14836                3.0             4.0            4.0         3      163   \n",
       "14837                1.0             1.0            1.0        18      175   \n",
       "14838                3.0             3.0            3.0         4      158   \n",
       "\n",
       "          length  lexical_diversity  n_sentences  nouns  verbs  adverbs  \\\n",
       "essay_id                                                                  \n",
       "14834        123               1.37            8     27     15        9   \n",
       "14835        180               1.55            9     41     25       12   \n",
       "14836        169               1.62            8     39     24        9   \n",
       "14837        199               1.69           11     34     25        8   \n",
       "14838        162               1.74           11     33     26        7   \n",
       "\n",
       "          adjectives  n_top500  \n",
       "essay_id                        \n",
       "14834             10         0  \n",
       "14835             13         0  \n",
       "14836             11         0  \n",
       "14837              5         0  \n",
       "14838             18         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "essays = pd.read_csv('../data/intermediate/prepped_essays.csv', index_col=0)\n",
    "\n",
    "# Set the essay id as the index of the dataframe\n",
    "essays.set_index('essay_id', inplace=True)\n",
    "\n",
    "essays.head()\n",
    "\n",
    "# binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 1., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.domain1_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryClassification(v):\n",
    "    if v < 3.0:\n",
    "        v = 0.0\n",
    "    elif v >= 3.0:\n",
    "        v = 1.0\n",
    "    return v\n",
    "\n",
    "essays['domain1_score'] = essays['domain1_score'].map(binaryClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.domain1_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelt</th>\n",
       "      <th>correct</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>n_top500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>18</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16629</th>\n",
       "      <td>18</td>\n",
       "      <td>136</td>\n",
       "      <td>154</td>\n",
       "      <td>1.77</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16630</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16631</th>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>105</td>\n",
       "      <td>1.48</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16632</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16633</th>\n",
       "      <td>14</td>\n",
       "      <td>144</td>\n",
       "      <td>158</td>\n",
       "      <td>1.82</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          misspelt  correct  length  lexical_diversity  n_sentences  nouns  \\\n",
       "essay_id                                                                     \n",
       "14834            6      116     123               1.37            8     27   \n",
       "14835           11      169     180               1.55            9     41   \n",
       "14836            3      163     169               1.62            8     39   \n",
       "14837           18      175     199               1.69           11     34   \n",
       "14838            4      158     162               1.74           11     33   \n",
       "...            ...      ...     ...                ...          ...    ...   \n",
       "16629           18      136     154               1.77            8     39   \n",
       "16630            3       64      66               1.25            3     17   \n",
       "16631            7       98     105               1.48            6     22   \n",
       "16632            2       66      68               1.26            2     13   \n",
       "16633           14      144     158               1.82           11     32   \n",
       "\n",
       "          verbs  adverbs  adjectives  n_top500  \n",
       "essay_id                                        \n",
       "14834        15        9          10         0  \n",
       "14835        25       12          13         0  \n",
       "14836        24        9          11         0  \n",
       "14837        25        8           5         0  \n",
       "14838        26        7          18         0  \n",
       "...         ...      ...         ...       ...  \n",
       "16629        14       15           7         1  \n",
       "16630         8        4           6         0  \n",
       "16631        10        9           7         0  \n",
       "16632        10        3           5         0  \n",
       "16633        30        9           7         0  \n",
       "\n",
       "[1800 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essays.drop(['domain1_score', '\tessay_set', 'essay','rater1_domain1\t', 'rater2_domain1'], axis=1)\n",
    "y = essays['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111111111111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred, y_test)\n",
    "accuracy_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_gini = accuracy_score(y_pred, y_test)\n",
    "accuracy_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79861111, 0.82986111, 0.84027778, 0.80208333, 0.81597222])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=2)\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "Accuracy_CV_scores = cross_val_score(dt_entropy, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1) \n",
    "\n",
    "Accuracy_CV_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=3\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=5)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=SEED)\n",
    "\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.825\n",
      "K Nearest Neighbours : 0.817\n",
      "Classification Tree : 0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_test) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=12)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.84\n",
      "OOB accuracy of bc: 0.82\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1, random_state=13)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Extract the OOB accuracy from bc\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) \n",
    "\n",
    "print('OOB accuracy of bc: {:.2f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='gini', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 2,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['gini', 'entropy'],\n",
       " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# criterion for information gain\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'criterion': criterion,\n",
    "               'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=2),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 80,\n",
       " 'criterion': 'gini',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 75  37]\n",
      " [ 21 227]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.67      0.72       112\n",
      "         1.0       0.86      0.92      0.89       248\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.82      0.79      0.80       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 74  38]\n",
      " [ 19 229]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.66      0.72       112\n",
      "         1.0       0.86      0.92      0.89       248\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.83      0.79      0.81       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate rf with best params from Random Search\n",
    "rf_random = RandomForestClassifier(criterion='entropy', \n",
    "                            n_estimators=800, \n",
    "                            min_samples_leaf=4, \n",
    "                            min_samples_split=5, \n",
    "                            max_features='sqrt',\n",
    "                            max_depth=None,\n",
    "                            bootstrap=True,\n",
    "                            random_state=2)\n",
    "\n",
    "# Fit rf to the training set    \n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf_random.feature_importances_, index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
